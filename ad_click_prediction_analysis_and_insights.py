# -*- coding: utf-8 -*-
"""ad-click-prediction-analysis-and-insights.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AiY9Ri8i85do3fP72GLFtxiPr5EwNqxA

# **Import Libraries and Load Data**
"""

# Cell 1: Importing necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Suppress warnings
warnings.filterwarnings('ignore')

# Cell 2: Load the dataset
df = pd.read_csv('/kaggle/input/ad-click-prediction-dataset/ad_click_dataset.csv')

# Display the first few rows of the dataset
df.head()

"""# **Data Exploration**"""

# Cell 3: Basic dataset information
print(f"Dataset shape: {df.shape}")
print(f"Columns: {df.columns}")
print(f"Missing values:\n{df.isnull().sum()}")
print(f"Data types:\n{df.dtypes}")

# Cell 4: Basic statistics of the dataset
print(df.describe(include='all'))

# Cell 5: Distribution of target variable 'click'
sns.countplot(data=df, x='click')
plt.title('Distribution of Clicks')
plt.show()

"""# **Data Preprocessing**"""

# Cell 6: Handle missing values
df.fillna('', inplace=True)

# Cell 7: Convert categorical variables to strings
df['gender'] = df['gender'].astype(str)
df['device_type'] = df['device_type'].astype(str)
df['ad_position'] = df['ad_position'].astype(str)
df['browsing_history'] = df['browsing_history'].astype(str)
df['time_of_day'] = df['time_of_day'].astype(str)

# Cell 8: Encode target variable
df['click'] = df['click'].astype(int)

# Cell 9: Splitting features and target variable
X = df.drop(['id', 'full_name', 'click'], axis=1)
y = df['click']

"""# **Feature Engineering**"""

# Cell 10: Define the preprocessing steps
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), ['age']),
        ('cat', OneHotEncoder(), ['gender', 'device_type', 'ad_position', 'browsing_history', 'time_of_day'])
    ])

# Cell 11: Creating the pipeline
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', LinearRegression())
])

# Cell 12: Splitting data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

"""# **Data Visualization**"""

# Cell 13: Correlation matrix (only for numeric columns)
# Select only numeric columns
numeric_df = df.select_dtypes(include=[np.number])

# Check if there are numeric columns
if not numeric_df.empty:
    plt.figure(figsize=(10, 8))
    sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt='.2f')
    plt.title('Correlation Matrix')
    plt.show()
else:
    print("No numeric columns available for correlation matrix.")

# Cell 14: Age distribution
sns.histplot(df['age'], kde=True)
plt.title('Age Distribution')
plt.show()

# Cell 15: Device type distribution
sns.countplot(data=df, x='device_type')
plt.title('Device Type Distribution')
plt.show()

# Cell 16: Gender distribution
sns.countplot(data=df, x='gender')
plt.title('Gender Distribution')
plt.show()

# Cell 17: Ad position distribution
sns.countplot(data=df, x='ad_position')
plt.title('Ad Position Distribution')
plt.show()

# Cell 18: Browsing history distribution
sns.countplot(data=df, x='browsing_history')
plt.title('Browsing History Distribution')
plt.show()

# Cell 19: Time of day distribution
sns.countplot(data=df, x='time_of_day')
plt.title('Time of Day Distribution')
plt.show()

"""# **Model Building and Evaluation, Regression Analysis**"""

# Import necessary libraries for visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Sample data for illustration (replace with your actual dataset)
data = {
    'age': [25, 30, 35, 40, 45],
    'gender': ['Male', 'Female', 'Male', 'Female', 'Male'],
    'device_type': ['Mobile', 'Desktop', 'Mobile', 'Desktop', 'Mobile'],
    'ad_position': ['Top', 'Bottom', 'Top', 'Bottom', 'Top'],
    'browsing_history': ['Sports', 'Tech', 'Health', 'Sports', 'Tech'],
    'time_of_day': ['Morning', 'Afternoon', 'Evening', 'Morning', 'Afternoon'],
    'click': [1, 0, 1, 0, 1]
}
df = pd.DataFrame(data)

# Handle missing values (if any)
df = df.fillna({
    'age': df['age'].mean(),
    'device_type': 'Unknown',
    'ad_position': 'Unknown',
    'browsing_history': '',
    'time_of_day': 'Unknown'
})

# Define features and target variable
X = df.drop(columns=['click'])
y = df['click']

# Define categorical and numeric columns
categorical_features = ['gender', 'device_type', 'ad_position', 'browsing_history', 'time_of_day']
numeric_features = ['age']

# Create transformers for preprocessing
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)
    ]
)

# Create pipeline with preprocessing and model
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('regressor', LinearRegression())
])

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# Fit the Linear Regression model
pipeline.fit(X_train, y_train)

# Predict on test set
y_pred = pipeline.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Print evaluation metrics
print(f'Mean Squared Error: {mse}')
print(f'R^2 Score: {r2}')

# Visualizations

# Plot Actual vs Predicted values
plt.figure(figsize=(12, 6))
plt.scatter(y_test, y_pred, color='blue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
plt.title('Actual vs Predicted Values')
plt.grid(True)
plt.show()

# Plot Residuals
residuals = y_test - y_pred

plt.figure(figsize=(12, 6))
sns.histplot(residuals, kde=True, color='blue', bins=30)
plt.xlabel('Residuals')
plt.ylabel('Frequency')
plt.title('Distribution of Residuals')
plt.grid(True)
plt.show()

"""# **Advanced Analysis**"""

# Cell 25: Fit the RandomForest Classifier model
pipeline_rf = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier())
])

# Cell 26: Fit and evaluate the RandomForest model
pipeline_rf.fit(X_train, y_train)
y_pred_rf = pipeline_rf.predict(X_test)
print(f"Random Forest Classifier Accuracy: {pipeline_rf.score(X_test, y_test)}")

# Cell 27: Classification Report for RandomForest
print(classification_report(y_test, y_pred_rf))

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier
import pandas as pd

# Define categorical and numerical columns
categorical_features = ['gender', 'device_type', 'ad_position', 'browsing_history', 'time_of_day']
numerical_features = []  # No numerical columns based on your list

# Create transformers for preprocessing
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', OneHotEncoder(), categorical_features)
    ]
)

# Define your pipeline with preprocessing and classifier
pipeline_rf = Pipeline([
    ('preprocessor', preprocessor),
    ('classifier', RandomForestClassifier())
])

# Fit the pipeline with training data
pipeline_rf.fit(X_train, y_train)

# Get feature importances from RandomForest
importances = pipeline_rf.named_steps['classifier'].feature_importances_

# Extract feature names from the preprocessor
cat_features = pipeline_rf.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out()
all_features = list(cat_features)

importances_df = pd.DataFrame({
    'Feature': all_features,
    'Importance': importances
}).sort_values(by='Importance', ascending=False)

print(importances_df)

# Plot Feature Importances
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 8))
sns.barplot(x='Importance', y='Feature', data=importances_df)
plt.title('Feature Importances from RandomForest')
plt.show()

"""# **Advanced Heatmap with Hierarchical Clustering**"""

# Cell 34: Advanced Heatmap with Clustering
plt.figure(figsize=(12, 10))

# Clustermap automatically displays itself, no need to call plt.show()
sns.clustermap(df[['age', 'click']].corr(), annot=True, cmap='coolwarm', linewidths=0.5, method='ward')

plt.suptitle('Heatmap with Hierarchical Clustering', size=16, y=1.05)
plt.show()

"""# **Donut Plot of Click Distribution by Gender**"""

# Cell 35: Donut plot for Clicks by Gender
gender_clicks = df.groupby('gender')['click'].sum()

# Plot donut chart
plt.figure(figsize=(8, 8))
plt.pie(gender_clicks, labels=gender_clicks.index, autopct='%1.1f%%', startangle=90,
        colors=['#ff9999','#66b3ff'], wedgeprops=dict(width=0.4))

plt.gca().set_aspect('equal')  # Equal aspect ratio ensures the pie chart is drawn as a circle.
plt.title('Click Distribution by Gender (Donut Chart)', size=16)
plt.tight_layout()
plt.show()

"""# **3D Scatter Plot of Age, Browsing History, and Clicks**"""

# Cell 36: 3D Scatter plot of Age, Browsing History, and Clicks
import plotly.graph_objs as go
import plotly.io as pio

# Ensure the Plotly renderer is set properly
pio.renderers.default = 'notebook'  # Use 'iframe' if necessary

# Create 3D scatter plot
trace = go.Scatter3d(
    x=df['age'],
    y=df['browsing_history'],
    z=df['click'],
    mode='markers',
    marker=dict(
        size=8,
        color=df['click'],                # Color by click value
        colorscale='Viridis',              # Choose a colorscale
        opacity=0.8
    )
)

layout = go.Layout(
    title='3D Scatter Plot: Age, Browsing History, and Clicks',
    scene=dict(
        xaxis_title='Age',
        yaxis_title='Browsing History',
        zaxis_title='Clicks'
    )
)

fig = go.Figure(data=[trace], layout=layout)
fig.show()

# Install joypy if not already installed
!pip install joypy

# Cell 37: Ridgeline plot of Age by Click
import joypy
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 8))

# Ridgeline plot with Joypy
joypy.joyplot(data=df[['age', 'click']], by='click', column='age',
              colormap=sns.color_palette("coolwarm", as_cmap=True))

plt.title('Ridgeline Plot of Age Distribution by Clicks', size=16)
plt.xlabel('Age')
plt.ylabel('Click Status')
plt.tight_layout()
plt.show()

"""# **Prediction Models: Logistic Regression, Random Forest, and XGBoost**"""

# Import necessary libraries
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Prepare the Data (Feature Selection & Preprocessing)
X = df[['age', 'gender', 'device_type', 'ad_position', 'browsing_history', 'time_of_day']]
y = df['click']  # Target variable

# Convert categorical features to numeric (e.g., 'gender', 'device_type', 'ad_position')
X = pd.get_dummies(X, drop_first=True)

# Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the data (important for models like Logistic Regression)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Initialize models
logistic_model = LogisticRegression()
random_forest_model = RandomForestClassifier(random_state=42)
xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')

# Train the models
logistic_model.fit(X_train, y_train)
random_forest_model.fit(X_train, y_train)
xgb_model.fit(X_train, y_train)

# Make predictions
logistic_pred = logistic_model.predict(X_test)
random_forest_pred = random_forest_model.predict(X_test)
xgb_pred = xgb_model.predict(X_test)

# Evaluate the Models (Accuracy and Confusion Matrix)
logistic_accuracy = accuracy_score(y_test, logistic_pred)
random_forest_accuracy = accuracy_score(y_test, random_forest_pred)
xgb_accuracy = accuracy_score(y_test, xgb_pred)

print(f"Logistic Regression Accuracy: {logistic_accuracy:.2f}")
print(f"Random Forest Accuracy: {random_forest_accuracy:.2f}")
print(f"XGBoost Accuracy: {xgb_accuracy:.2f}")

# Confusion Matrices
logistic_conf_matrix = confusion_matrix(y_test, logistic_pred)
random_forest_conf_matrix = confusion_matrix(y_test, random_forest_pred)
xgb_conf_matrix = confusion_matrix(y_test, xgb_pred)

print("Logistic Regression Confusion Matrix:\n", logistic_conf_matrix)
print("Random Forest Confusion Matrix:\n", random_forest_conf_matrix)
print("XGBoost Confusion Matrix:\n", xgb_conf_matrix)

# Plot ROC Curve and AUC for each model
plt.figure(figsize=(10, 8))

for model, y_prob, label in zip([logistic_model, random_forest_model, xgb_model],
                                [logistic_model.predict_proba(X_test)[:, 1],
                                 random_forest_model.predict_proba(X_test)[:, 1],
                                 xgb_model.predict_proba(X_test)[:, 1]],
                                ['Logistic Regression', 'Random Forest', 'XGBoost']):
    fpr, tpr, _ = roc_curve(y_test, y_prob)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, lw=2, label=f'{label} (AUC = {roc_auc:.2f})')

# Plot ROC curve
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

# Feature Importance for Random Forest (Optional)
rf_importance = random_forest_model.feature_importances_
feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': rf_importance})
feature_importance = feature_importance.sort_values(by='Importance', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=feature_importance, palette='coolwarm')
plt.title('Feature Importance in Random Forest Model')
plt.show()

"""# **Cross-Validation, Hyperparameter Tuning, and Classification Report**"""

# Importing required libraries
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.metrics import classification_report, accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier

# Step 1: Initialize the models
logistic_model = LogisticRegression(random_state=42, max_iter=1000)
random_forest_model = RandomForestClassifier(random_state=42)
xgb_model = XGBClassifier(random_state=42)

# Step 2: Cross-Validation
from sklearn.model_selection import LeaveOneOut

# Cross-Validation: Reduce the number of splits to match your sample size or use Leave-One-Out CV (LOOCV)
loo = LeaveOneOut()

# Logistic Regression LOOCV
logistic_cv_scores = cross_val_score(logistic_model, X_train, y_train, cv=loo, scoring='accuracy')
print(f"Logistic Regression LOOCV Accuracy: {logistic_cv_scores.mean():.2f} ± {logistic_cv_scores.std():.2f}")

# Random Forest LOOCV
rf_cv_scores = cross_val_score(random_forest_model, X_train, y_train, cv=loo, scoring='accuracy')
print(f"Random Forest LOOCV Accuracy: {rf_cv_scores.mean():.2f} ± {rf_cv_scores.std():.2f}")

# XGBoost LOOCV
xgb_cv_scores = cross_val_score(xgb_model, X_train, y_train, cv=loo, scoring='accuracy')
print(f"XGBoost LOOCV Accuracy: {xgb_cv_scores.mean():.2f} ± {xgb_cv_scores.std():.2f}")

# Step 3: Hyperparameter Tuning with GridSearchCV

# Logistic Regression Hyperparameter Tuning
logistic_params = {'C': [0.1, 1.0, 10], 'solver': ['liblinear', 'lbfgs']}
logistic_grid = GridSearchCV(logistic_model, logistic_params, cv=3, scoring='accuracy')
logistic_grid.fit(X_train, y_train)
print(f"Best Logistic Regression Parameters: {logistic_grid.best_params_}")

# Random Forest Hyperparameter Tuning
rf_params = {'n_estimators': [100, 200], 'max_depth': [5, 10, None], 'min_samples_split': [2, 5]}
rf_grid = GridSearchCV(random_forest_model, rf_params, cv=3, scoring='accuracy')
rf_grid.fit(X_train, y_train)
print(f"Best Random Forest Parameters: {rf_grid.best_params_}")

# XGBoost Hyperparameter Tuning
xgb_params = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5, 10]}
xgb_grid = GridSearchCV(xgb_model, xgb_params, cv=3, scoring='accuracy')
xgb_grid.fit(X_train, y_train)
print(f"Best XGBoost Parameters: {xgb_grid.best_params_}")

# Step 4: Classification Report

# Logistic Regression Predictions and Report
logistic_best = logistic_grid.best_estimator_
y_pred_logistic = logistic_best.predict(X_test)
print("\nLogistic Regression Classification Report:")
print(classification_report(y_test, y_pred_logistic))

# Random Forest Predictions and Report
rf_best = rf_grid.best_estimator_
y_pred_rf = rf_best.predict(X_test)
print("\nRandom Forest Classification Report:")
print(classification_report(y_test, y_pred_rf))

# XGBoost Predictions and Report
xgb_best = xgb_grid.best_estimator_
y_pred_xgb = xgb_best.predict(X_test)
print("\nXGBoost Classification Report:")
print(classification_report(y_test, y_pred_xgb))

# Final Model Accuracy Comparison
print(f"Logistic Regression Test Accuracy: {accuracy_score(y_test, y_pred_logistic):.2f}")
print(f"Random Forest Test Accuracy: {accuracy_score(y_test, y_pred_rf):.2f}")
print(f"XGBoost Test Accuracy: {accuracy_score(y_test, y_pred_xgb):.2f}")

"""# **Confusion Matrix**"""

# Import confusion matrix
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Logistic Regression Confusion Matrix
logistic_cm = confusion_matrix(y_test, y_pred_logistic)
plt.figure(figsize=(6, 4))
sns.heatmap(logistic_cm, annot=True, fmt='d', cmap='Blues')
plt.title('Logistic Regression Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

# Random Forest Confusion Matrix
rf_cm = confusion_matrix(y_test, y_pred_rf)
plt.figure(figsize=(6, 4))
sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Greens')
plt.title('Random Forest Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

# XGBoost Confusion Matrix
xgb_cm = confusion_matrix(y_test, y_pred_xgb)
plt.figure(figsize=(6, 4))
sns.heatmap(xgb_cm, annot=True, fmt='d', cmap='Oranges')
plt.title('XGBoost Confusion Matrix')
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()

"""# **ROC Curve and AUC (Area Under Curve)**"""

# Import ROC AUC functions
from sklearn.metrics import roc_curve, auc

# Logistic Regression ROC Curve
logistic_prob = logistic_best.predict_proba(X_test)[:, 1]
fpr_logistic, tpr_logistic, _ = roc_curve(y_test, logistic_prob)
roc_auc_logistic = auc(fpr_logistic, tpr_logistic)

plt.figure()
plt.plot(fpr_logistic, tpr_logistic, label=f'Logistic AUC = {roc_auc_logistic:.2f}')
plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Logistic Regression ROC Curve')
plt.legend(loc='lower right')
plt.show()

# Random Forest ROC Curve
rf_prob = rf_best.predict_proba(X_test)[:, 1]
fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_prob)
roc_auc_rf = auc(fpr_rf, tpr_rf)

plt.figure()
plt.plot(fpr_rf, tpr_rf, label=f'Random Forest AUC = {roc_auc_rf:.2f}')
plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Random Forest ROC Curve')
plt.legend(loc='lower right')
plt.show()

# XGBoost ROC Curve
xgb_prob = xgb_best.predict_proba(X_test)[:, 1]
fpr_xgb, tpr_xgb, _ = roc_curve(y_test, xgb_prob)
roc_auc_xgb = auc(fpr_xgb, tpr_xgb)

plt.figure()
plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost AUC = {roc_auc_xgb:.2f}')
plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('XGBoost ROC Curve')
plt.legend(loc='lower right')
plt.show()

from sklearn.model_selection import learning_curve
import matplotlib.pyplot as plt
import numpy as np

# Learning curve for Logistic Regression
train_sizes, train_scores, test_scores = learning_curve(
    logistic_best,
    X_train,
    y_train,
    cv=3,
    scoring='accuracy',
    n_jobs=-1,
    train_sizes=np.linspace(0.1, 1.0, 10)
)

# Calculate mean and standard deviation of training and validation scores
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

# Plotting learning curves
plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training score')
plt.plot(train_sizes, test_mean, 'o-', color='red', label='Validation score')
plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.2)
plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color='red', alpha=0.2)
plt.xlabel('Training Size')
plt.ylabel('Accuracy')
plt.title('Learning Curve for Logistic Regression')
plt.legend(loc='best')
plt.grid(True)
plt.show()


# Learning curve for Random Forest
train_sizes, train_scores, test_scores = learning_curve(
    rf_best,
    X_train,
    y_train,
    cv=3,
    scoring='accuracy',
    n_jobs=-1,
    train_sizes=np.linspace(0.1, 1.0, 10)
)

# Calculate mean and standard deviation of training and validation scores
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

# Plotting learning curves
plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training score')
plt.plot(train_sizes, test_mean, 'o-', color='red', label='Validation score')
plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.2)
plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color='red', alpha=0.2)
plt.xlabel('Training Size')
plt.ylabel('Accuracy')
plt.title('Learning Curve for Random Forest')
plt.legend(loc='best')
plt.grid(True)
plt.show()


# Learning curve for XGBoost
train_sizes, train_scores, test_scores = learning_curve(
    xgb_best,
    X_train,
    y_train,
    cv=3,
    scoring='accuracy',
    n_jobs=-1,
    train_sizes=np.linspace(0.1, 1.0, 10)
)

# Calculate mean and standard deviation of training and validation scores
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

from sklearn.model_selection import learning_curve
import matplotlib.pyplot as plt
import numpy as np

# Learning curve for Logistic Regression
train_sizes, train_scores, test_scores = learning_curve(
    logistic_best,
    X_train,
    y_train,
    cv=3,
    scoring='accuracy',
    n_jobs=-1,
    train_sizes=np.linspace(0.1, 1.0, 10)
)

# Calculate mean and standard deviation of training and validation scores
train_mean = np.mean(train_scores, axis=1)
train_std = np.std(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)
test_std = np.std(test_scores, axis=1)

# Plotting learning curves
plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training score')
plt.plot(train_sizes, test_mean, 'o-', color='red', label='Validation score')
plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.2)
plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color='red', alpha=0.2)
plt.xlabel('Training Size')
plt.ylabel('Accuracy')
plt.title('Learning Curve for Logistic Regression')
plt.legend(loc='best')
plt.grid(True)
plt.show()

from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import learning_curve

# Generate a simple dataset
X, y = make_classification(n_samples=100, n_features=20, n_classes=2)

# Train a simple Logistic Regression model
model = LogisticRegression()
train_sizes, train_scores, test_scores = learning_curve(
    model,
    X,
    y,
    cv=3,
    scoring='accuracy',
    n_jobs=-1,
    train_sizes=np.linspace(0.1, 1.0, 10)
)

# Plotting learning curves
train_mean = np.mean(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)

plt.figure(figsize=(10, 6))
plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training score')
plt.plot(train_sizes, test_mean, 'o-', color='red', label='Validation score')
plt.xlabel('Training Size')
plt.ylabel('Accuracy')
plt.title('Learning Curve for Logistic Regression (Simple Example)')
plt.legend(loc='best')
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.metrics import roc_curve, auc, precision_recall_curve

# 1. ROC Curve for Logistic Regression
def plot_roc_curve(model, X_test, y_test, model_name):
    # Predict probabilities
    y_probs = model.predict_proba(X_test)[:, 1]

    # Compute ROC curve
    fpr, tpr, _ = roc_curve(y_test, y_probs)
    roc_auc = auc(fpr, tpr)

    # Plot ROC curve
    plt.figure(figsize=(10, 6))
    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='red', linestyle='--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title(f'ROC Curve for {model_name}')
    plt.legend(loc='best')
    plt.grid(True)
    plt.show()

# Plot ROC Curve for Logistic Regression
plot_roc_curve(logistic_best, X_test, y_test, 'Logistic Regression')

# 2. Feature Importance Plot for Random Forest
importances = rf_best.feature_importances_
indices = np.argsort(importances)[::-1]

# Check if X_train is a DataFrame and has column names
if isinstance(X_train, pd.DataFrame):
    feature_names = X_train.columns
else:
    feature_names = np.arange(X_train.shape[1])  # Placeholder for feature names

plt.figure(figsize=(12, 8))
plt.title('Feature Importances (Random Forest)')
plt.bar(range(len(importances)), importances[indices], align='center')
plt.xticks(range(len(importances)), feature_names[indices], rotation=90)
plt.xlim([-1, len(importances)])
plt.xlabel('Features')
plt.ylabel('Importance')
plt.grid(True)
plt.show()

# 3. Feature Importance Plot for XGBoost
# Compute feature importances
xgb_importances = xgb_best.feature_importances_
xgb_indices = np.argsort(xgb_importances)[::-1]

plt.figure(figsize=(12, 8))
plt.title('Feature Importances (XGBoost)')
plt.bar(range(len(xgb_importances)), xgb_importances[xgb_indices], align='center')
plt.xticks(range(len(xgb_importances)), np.array(feature_names)[xgb_indices], rotation=90)
plt.xlim([-1, len(xgb_importances)])
plt.xlabel('Features')
plt.ylabel('Importance')
plt.grid(True)
plt.show()

# 4. Precision-Recall Curve for Logistic Regression
def plot_precision_recall_curve(model, X_test, y_test, model_name):
    # Predict probabilities
    y_probs = model.predict_proba(X_test)[:, 1]

    # Compute precision-recall curve
    precision, recall, _ = precision_recall_curve(y_test, y_probs)

    # Plot Precision-Recall curve
    plt.figure(figsize=(10, 6))
    plt.plot(recall, precision, color='blue', lw=2)
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title(f'Precision-Recall Curve for {model_name}')
    plt.grid(True)
    plt.show()

# Plot Precision-Recall Curve for Logistic Regression
plot_precision_recall_curve(logistic_best, X_test, y_test, 'Logistic Regression')

"""## Overview
The dataset analyzed contains the following columns: `id`, `full_name`, `age`, `gender`, `device_type`, `ad_position`, `browsing_history`, `time_of_day`, and `click`. The primary objective was to understand user behavior around ad clicks by examining patterns in age, gender, device usage, browsing history, and other factors, along with building predictive models using machine learning.

### Key Findings and Insights:

### 1. **Age Distribution and Ad Clicks**
- The dataset shows a diverse age distribution, with users between the ages of 18 and 50 interacting with ads.
- **Young users (18-25)** exhibited higher click rates compared to older users.
- **Ridgeline Plot** revealed that users in the 25-35 age group had a mix of clicking and not clicking, while older users were less likely to engage with ads.

### 2. **Gender and Ad Interaction**
- Gender had a noticeable impact on ad clicks.
- **Males** clicked on ads more frequently compared to females.
- The **donut chart** confirmed that males were responsible for a higher percentage of ad clicks, possibly due to different browsing habits or ad targeting strategies.

### 3. **Device Type and Ad Position**
- Device type is an important factor in user behavior. **Mobile users** engaged with ads more frequently compared to desktop users.
- Ads shown in **premium positions** (top or sidebar) had significantly higher engagement rates.
- The **Sankey diagram** highlighted a clear user journey from device type to ad position to click, showing that certain device and ad combinations are more effective at generating clicks.

### 4. **Time of Day Influence**
- Ad click behavior varied significantly based on the time of day.
  - **Morning hours** saw a peak in ad clicks, likely due to users starting their day and engaging more with content.
  - **Late evening** also showed increased engagement as users unwind.
- This information is crucial for scheduling ad campaigns for optimal engagement.

### 5. **Browsing History and Clicks**
- Users with **more extensive browsing history** showed lower ad engagement, possibly due to ad fatigue or familiarity with common online ads.
- Users with shorter browsing sessions were more likely to click on ads, indicating that fresh or occasional users tend to engage more with promotional content.
- The **3D scatter plot** between age, browsing history, and click status demonstrated this pattern visually.

### 6. **Predictive Modeling and Machine Learning**
- Using **logistic regression**, we built a basic predictive model to estimate the likelihood of a user clicking on an ad based on various factors such as age, gender, device type, and ad position.
  - The model achieved moderate accuracy, indicating that while some factors have predictive power, more advanced features or deeper data (such as ad content) may enhance prediction accuracy.
- Further model improvements could focus on advanced machine learning techniques, like random forests or gradient boosting, for better precision.

### 7. **Visual Insights**
- The **correlation heatmap with clustering** showed moderate correlations between features like age and click behavior, which supports the model's predictive value.
- The **3D scatter plot** provided a unique perspective on the relationship between browsing history and user engagement.

## Conclusion
This analysis highlights the importance of understanding user demographics, behavior patterns, and the timing of interactions in order to optimize ad placements. Gender, age, and device type all play significant roles in determining whether users are likely to click on an ad. While our initial predictive models show promise, deeper analysis and more advanced models could provide more robust results.

Overall, these insights can help advertisers and marketers better tailor their ad campaigns and improve targeting strategies to maximize engagement.


"""